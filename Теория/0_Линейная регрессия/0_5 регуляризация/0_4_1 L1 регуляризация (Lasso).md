## L1 регуляризация
**L1 регуляризация** - это пример регуляризации, при котором к [[0_2_1 Что такое лосс функция|лосс функции]] ==добавляют дополнительное слагаемое в виде суммы абсолютных значений весов==. 

[[0_1_3_0 Формула L1 регуляции(Lasso)|формула]]:
$$
L+\lambda \cdot \sum_{j=1}^n \left|w_{j} \right|
$$
где: 
- λ - коэффициент регуляризации, чем больше, тем жёстче регуляризация  
### Плюсы L1 регуляризации
- ==Способна занулять веса==, тем самым упрощая модель. Если не все признаки важны, то это плюс. Но так же может быть и минусом, если признаки всё-таки важны([[0_4_2 L2 регуляризация (Ridge)|L2 регуляция]])
- ==Уменьшает переобучение==, делая модель проще 
### Минусы L1 регуляризации
- ==Редко применяется вместе с [[0_4 градиентный спуск|градиентным спуском]]==
- ==Хуже работает, если признаки коррелируют между собой(x1 зависит от x2)==, так как зануляет только 1 из них 
- ==Страдает, если плохой масштаб данных==
### Пример вычисления L1 регуляризации

$$
\lambda \sum_{j=1}^{2} |w_j| = 0.5 \cdot (|2| + |-3|) = 0.5 \cdot (2 + 3) = 0.5 \cdot 5 = 2.5
$$

L1 является мощным инструментом регуляризации, так как помогает эффективно отбирать признаки и уменьшать переобучение.
